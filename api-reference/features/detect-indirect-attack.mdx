---
title: "Detect Indirect Attack"
hideTitle: false
---

Glaider identifies potential indirect prompt injection attacks that could manipulate AI model behavior through secondary inputs like documents or third-party API data.

## Endpoint

```
POST /v1/detect-indirect-attack
```

**Note**: Replace the base URL (e.g., `http://api.glaider.it`) with your actual server address.

## Authentication

The API requires authentication via an API key.

- **Header**: `Authorization: Bearer YOUR_API_KEY`
- Replace `YOUR_API_KEY` with your actual API key.

## Headers

| Header          | Value                  |
|-----------------|------------------------|
| Authorization   | Bearer `YOUR_API_KEY`  |
| Content-Type    | `multipart/form-data`  |

**Note**: When uploading files, you should not manually set the `Content-Type` header; `requests` or your HTTP client library will handle it when using `multipart/form-data`.

## Request Parameters

### Form Data

| Parameter      | Type      | Required | Description                                                                                                   |
|----------------|-----------|----------|---------------------------------------------------------------------------------------------------------------|
| file           | file      | **Yes**  | The document file to be analyzed for potential indirect prompt injection. Accepted formats: PDF, DOCX, TXT, etc. |

**Note**: The file should be uploaded using a `multipart/form-data` form submission.

### Other Parameters

The current implementation focuses on analyzing the uploaded document. Additional parameters like `zero_latency`, `strictness`, `tag`, etc., are set within the server code and are not exposed as request parameters for this endpoint.

## Response

### Success Response

- **Status Code**: `200 OK`
- **Content-Type**: `application/json`
- **Body**:

```json
{
  "summary": {
    "total_chunks": 5,
    "safe_chunks": 4,
    "unsafe_chunks": 1,
    "results": [
      {
        "chunk_index": 0,
        "is_prompt_injection": false,
        "analysis_id": "abcd1234"
      },
      {
        "chunk_index": 1,
        "is_prompt_injection": true,
        "analysis_id": "efgh5678"
      },
      // Additional chunk results...
    ],
    "complete_text": "Full extracted text from the document..."
  },
  "unsafe_chunks": [
    {
      "chunk_index": 1,
      "text": "Text of the unsafe chunk...",
      "analysis_id": "efgh5678"
    }
    // Additional unsafe chunks...
  ]
}
```

### Error Responses

#### 400 Bad Request

```json
{
  "error": "No file part in the request"
}
```

#### 500 Internal Server Error

```json
{
  "error": "Internal server error"
}
```

## Example Usage

### Python Example

```python
import requests

BASE_URL = "http://api.glaider.it/v1"
API_KEY = "YOUR_API_KEY"

headers = {
    "Authorization": f"Bearer {API_KEY}",
    # Do not set 'Content-Type' header when uploading files
}

def test_detect_indirect_attack():
    url = f"{BASE_URL}/detect-indirect-attack"
    # Replace 'path_to_your_file.pdf' with the actual path to your test file
    with open('path_to_your_file.pdf', 'rb') as f:
        files = {
            'file': ('your_file.pdf', f)
        }

        response = requests.post(url, files=files, headers=headers)

        print("Response Status Code:", response.status_code)
        print("Response JSON:", response.json())

if __name__ == "__main__":
    test_detect_indirect_attack() 
```

**Explanation:**

- **Endpoint URL**: Adjusted to point to `http://api.glaider.it/v1/detect-indirect-attack`.
- **API Key**: Replace `"YOUR_API_KEY"` with your actual API key.
- **Headers**: Only the `Authorization` header is set. Do not manually set the `Content-Type` header when uploading files.
- **File Upload**: The file is sent in the `files` parameter using `multipart/form-data`.
- **Response Handling**: The script prints out the status code and the JSON response.

**Sample Output:**

```json
Response Status Code: 200
Response JSON: {
  "summary": {
    "total_chunks": 3,
    "safe_chunks": 2,
    "unsafe_chunks": 1,
    "results": [
      {
        "chunk_index": 0,
        "is_prompt_injection": false,
        "analysis_id": "a1b2c3d4"
      },
      {
        "chunk_index": 1,
        "is_prompt_injection": true,
        "analysis_id": "e5f6g7h8"
      },
      {
        "chunk_index": 2,
        "is_prompt_injection": false,
        "analysis_id": "i9j0k1l2"
      }
    ],
    "complete_text": "Full extracted text from the document..."
  },
  "unsafe_chunks": [
    {
      "chunk_index": 1,
      "text": "Text of the unsafe chunk...",
      "analysis_id": "e5f6g7h8"
    }
  ]
}
```

## Response Fields Description

- **summary** (`object`): Contains the summary of the analysis.
  - **total_chunks** (`integer`): Total number of text chunks analyzed.
  - **safe_chunks** (`integer`): Number of chunks classified as safe.
  - **unsafe_chunks** (`integer`): Number of chunks classified as unsafe (potential indirect attacks).
  - **results** (`array`): List of results for each chunk.
    - **chunk_index** (`integer`): Index of the chunk in the document.
    - **is_prompt_injection** (`boolean`): `true` if the chunk is classified as an indirect attack.
    - **analysis_id** (`string`): Unique identifier for the analysis of this chunk.
  - **complete_text** (`string`): The full text extracted from the uploaded document.
- **unsafe_chunks** (`array`): Details of the chunks identified as unsafe.
  - **chunk_index** (`integer`): Index of the unsafe chunk.
  - **text** (`string`): Text content of the unsafe chunk.
  - **analysis_id** (`string`): Unique identifier for the analysis of this chunk.
- **error** (`string`): Error message in case of an error.

## Additional Information

- **File Support**: The service supports various document formats like PDF, DOCX, TXT, etc.
- **Chunking Logic**: The text extracted from the document is split into chunks of up to 480 characters each for analysis.
- **Analysis Process**: Each chunk is analyzed for prompt injection using the existing prompt injection detection mechanisms.
- **Asynchronous Processing**: The current implementation processes all chunks synchronously and returns the aggregated result.

## Usage Notes

- **Authentication**: Make sure to include your API key in the `Authorization` header.
- **File Upload**: Use `multipart/form-data` to upload the file.
- **Response Handling**: Check the `unsafe_chunks` and `summary` in the response to understand the analysis outcome.
- **Error Handling**: If an error occurs, the response will contain an `error` field with the error message.
- **Performance**: The total execution time may vary depending on the size of the document and the number of chunks.
